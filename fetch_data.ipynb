{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetching and Processing Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process BERT vec with introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elim the characters in sentences with the Baidu API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dat = pd.read_csv(\"data/desc.csv\", index_col=0)\n",
    "intro_dat = raw_dat[[\"ts_code\", \"introduction\", \"business_scope\", \"main_business\"]]\n",
    "intro_dat = intro_dat.fillna(\"\")\n",
    "intro_dat.loc[:, \"intro_all\"] = (\n",
    "    intro_dat.loc[:, \"introduction\"]\n",
    "    + intro_dat.loc[:, \"business_scope\"]\n",
    "    + intro_dat.loc[:, \"main_business\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_dat.to_csv('raw_intro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aip import AipNlp\n",
    "\n",
    "APP_ID = \"18643028\"\n",
    "API_KEY = \"DZ9xbDqRVDhTA5OKO56zwv1k\"\n",
    "SECRET_KEY = \"KG59O3eaWioaQdp7fChEOpZAvKF3i14n\"\n",
    "\n",
    "client = AipNlp(APP_ID, API_KEY, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3924/3924 [1:05:29<00:00,  1.00s/companies]\n"
     ]
    }
   ],
   "source": [
    "from ratelimit import limits, sleep_and_retry\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEC_CALL_LIMIT = {\"calls\": 1, \"seconds\": 1}\n",
    "\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=SEC_CALL_LIMIT[\"calls\"], period=SEC_CALL_LIMIT[\"seconds\"])\n",
    "def get_lexer(intro):\n",
    "    get_code = client.lexer(intro)\n",
    "    if \"error_code\" not in get_code:\n",
    "        return get_code\n",
    "    else:\n",
    "        raise Exception(\"API response: {}\".format(get_code))\n",
    "\n",
    "\n",
    "seperate_dict = {}\n",
    "for i in tqdm(range(intro_dat.shape[0]), unit=\"companies\"):\n",
    "    seperate_dict[intro_dat.iloc[i, 0]] = get_lexer(intro_dat.iloc[i, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open(\"raw_seperate\", \"wb\")\n",
    "pickle.dump(seperate_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess word property data queried from Baidu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def delete_char(single_dict):\n",
    "    elim_ticker = [\"c\", \"u\", \"xc\", \"w\"]\n",
    "    return True if single_dict[\"pos\"] in elim_ticker else False\n",
    "\n",
    "\n",
    "def delete_join_char(stock_result_list):\n",
    "    processed_sentence = \"\"\n",
    "    for single_word in stock_result_list:\n",
    "        if not delete_char(single_word):\n",
    "            processed_sentence += single_word[\"item\"]\n",
    "    return processed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing intro words: 100%|██████████| 3924/3924 [00:03<00:00, 1097.63companies/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned_dat = pd.DataFrame(columns=[\"ticker\", \"intro\"])\n",
    "for comp in tqdm(seperate_dict, desc=\"Processing intro words\", unit=\"companies\"):\n",
    "    new_sentence = delete_join_char(seperate_dict[comp][\"items\"])\n",
    "    new_df = pd.DataFrame([[comp, new_sentence]], columns=[\"ticker\", \"intro\"])\n",
    "    cleaned_dat = cleaned_dat.append(new_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>intro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603363.SH</td>\n",
       "      <td>公司是一家以标准化规范化集约化产业化为导向高科技农牧企业公司主营业务包括饲料动保养猪原料贸易...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>603128.SH</td>\n",
       "      <td>公司是中国本土最具规模提供跨境一站式综合物流服务企业一公司主营跨境现代综合第三方物流具体提供...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688039.SH</td>\n",
       "      <td>公司是一家专注于智能视频技术算法研究面向传媒文化公共安全行业国家高新技术企业公司经营模式主要...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603127.SH</td>\n",
       "      <td>公司主要从事以药物非临床安全性评价服务为主药物临床前研究服务实验动物附属产品销售业务其中药物...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>601068.SH</td>\n",
       "      <td>公司是中国铝业集团有限公司工程技术板块是集测绘勘察工程设计工程施工工程总承包科技研发装备制造...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker                                              intro\n",
       "0  603363.SH  公司是一家以标准化规范化集约化产业化为导向高科技农牧企业公司主营业务包括饲料动保养猪原料贸易...\n",
       "1  603128.SH  公司是中国本土最具规模提供跨境一站式综合物流服务企业一公司主营跨境现代综合第三方物流具体提供...\n",
       "2  688039.SH  公司是一家专注于智能视频技术算法研究面向传媒文化公共安全行业国家高新技术企业公司经营模式主要...\n",
       "3  603127.SH  公司主要从事以药物非临床安全性评价服务为主药物临床前研究服务实验动物附属产品销售业务其中药物...\n",
       "4  601068.SH  公司是中国铝业集团有限公司工程技术板块是集测绘勘察工程设计工程施工工程总承包科技研发装备制造..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dat.to_csv(\"clean_desc_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Price data from Tushare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better to quere with R tidyquant library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "ts.set_token('1dad4f86f90aa240de1a30832a5e1ff4e13c646685852f4f7ac30832')\n",
    "pro=ts.pro_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\programs\\Miniconda3\\envs\\hejj3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cleaned_dat=pd.read_csv('data/clean_desc_data.csv')\n",
    "short = cleaned_dat[cleaned_dat[\"intro\"].str.len() <= 512]\n",
    "short['ticker'].to_csv('queuename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ratelimit import limits, sleep_and_retry\n",
    "\n",
    "SEC_CALL_LIMIT = {\"calls\": 500, \"seconds\": 60}\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=SEC_CALL_LIMIT[\"calls\"], period=SEC_CALL_LIMIT[\"seconds\"])\n",
    "def get_price_data(ticker,start_date,end_date):\n",
    "    return pro.daily_basic(ts_code=ticker, start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "prices_df=[]\n",
    "start_date='20190630'\n",
    "end_date='20191231'\n",
    "for ticker in tqdm(namelist,desc='Downloading prices',unit='companies'):\n",
    "    prices_df.append(get_price_data(ticker,start_date,end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
